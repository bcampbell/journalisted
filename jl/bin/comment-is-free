#!/usr/bin/env python2.4
#
# Tool to scrape journo info from the guardian commentisfree site.
#

import re
from datetime import datetime
import sys
import os
import simplejson

sys.path.append( "../pylib" )
from BeautifulSoup import BeautifulSoup, SoupStrainer
from JL import ukmedia, ArticleDB
from JL.Journo import FindJournoException


CONTRIBUTORS_URL = 'http://commentisfree.guardian.co.uk/contributors_a-z.html'


def run():
    """Parse the CIF contributors a-z page, update journo_bio and journo_weblink."""

    if os.path.isfile('file:contributors_a-z.html'):
        html = 'file:contributors_a-z.html'
    else:
        html = ukmedia.FetchURL(CONTRIBUTORS_URL)
    soup = BeautifulSoup(html)

    db = ArticleDB.ArticleDB()
    cursor = db.conn.cursor()
    cursor.execute("SELECT id FROM organisation WHERE shortname='guardian'")
    guardian_srcorgid = cursor.fetchone()[0]
    cursor.close()
    
    authordivs = soup.findAll('div', {'class':'authorazentry'})

    cursor = db.conn.cursor()
    cursor.execute('BEGIN')

    saved, saved_bios, saved_weblinks, exceptions = 0, 0, 0, 0
    MAX_EXCEPTIONS = 10
    for authordiv in authordivs:
        biodiv = authordiv.find('div', {'class': 'authorbio'})
        
        name = ukmedia.DescapeHTML(authordiv.h1.a.string)
        profile_url = authordiv.find( text="Profile" ).parent['href']
        bio = biodiv.p.renderContents(None)
        
        try:
            journo_id = ArticleDB.StoreJourno(db.conn, name, guardian_srcorgid)
            saved_bio, saved_weblink = \
               save_journo_info(cursor, name, journo_id, profile_url, bio)
            saved += 1
            saved_bios += int(saved_bio)
            saved_weblink += int(saved_weblink)
        except FindJournoException, e:
            ukmedia.DBUG2(u"Failed to get journo_id for %s:\n    %s\n" % (name, e))
            exceptions += 1
            if exceptions > MAX_EXCEPTIONS:
                raise  # rollback

    cursor.execute('COMMIT')
    cursor.close()
    ukmedia.DBUG2(
        'Done. %d journos handled (%d bios, %d weblinks), %d exceptions.\n'
                  % (saved, saved_bios, saved_weblinks, exceptions))

def save_journo_info(cursor, name, journo_id, profile_url, bio):
    assert journo_id is not None
    saved_bio, saved_weblink = False, False
    blog_url = profile_url.replace('/profile.html', '/')
    # Not storing: feed_url = profile_url.replace('/profile.html', '/index.xml')

    context = {'journo_name': name,
               'added': datetime.now().isoformat()[:19],
               'scraper': '/bin/comment-is-free'}
    context = simplejson.dumps(context)
    
    # Insert bio with srcurl=profile_url into journo_bio table:
    cursor.execute("SELECT id FROM journo_bio WHERE type='cif:contributors-az' "
                   "AND journo_id=%d" % journo_id)
    if cursor.fetchall():
        ukmedia.DBUG2('  not updating bio for %s\n' % name)
    else:
        ukmedia.DBUG2('  NEW bio for %s\n' % name)
        cursor.execute(
            "INSERT INTO journo_bio"
                "(context, bio, journo_id, srcurl, type, approved) "
            "VALUES (%s, %s, %s, %s, 'cif:contributors-az', false)",
            [context, bio.encode('utf-8'), journo_id, profile_url.encode('utf-8')])
        saved_bio = True

    # Insert link for blog_url into journo_weblink
    cursor.execute("SELECT id FROM journo_weblink WHERE type='cif:blog:html' "
                   "AND journo_id=%d" % journo_id)
    if cursor.fetchall():
        ukmedia.DBUG2('  not updating weblink for %s\n' % name)
    else:
        ukmedia.DBUG2('  NEW weblink: %s: %s\n' % (name, blog_url))
        cursor.execute(
            "INSERT INTO journo_weblink"
                "(journo_id, url, source, description, type, approved)"
            "VALUES (%s, %s, %s, %s, 'cif:blog:html', false)",
            [journo_id, blog_url, CONTRIBUTORS_URL, '"Comment is free" blog'])
        saved_weblink = True
    ukmedia.DBUG2('\n')
    return saved_bio, saved_weblink

if __name__=='__main__':
    if '--help' in sys.argv or '-h' in sys.argv:
        sys.exit('usage: comment-is-free\n'
                 'Reads the contributors A-Z page, updates database.')
    run()

